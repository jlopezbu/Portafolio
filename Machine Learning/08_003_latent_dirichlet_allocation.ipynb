{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d2eab6e4-eb9f-43cc-883d-2c2d07b8db4f",
      "metadata": {
        "tags": [],
        "id": "d2eab6e4-eb9f-43cc-883d-2c2d07b8db4f"
      },
      "source": [
        "Latent Dirichlet Allocation\n",
        "==="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d51828b9-1927-46ca-99b7-f0457bf1fdcd",
      "metadata": {
        "id": "d51828b9-1927-46ca-99b7-f0457bf1fdcd"
      },
      "source": [
        "Preparación\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "86a3a063-4324-4f75-af9f-581c698abc5f",
      "metadata": {
        "id": "86a3a063-4324-4f75-af9f-581c698abc5f",
        "outputId": "48c0f9f2-13e4-4e78-f8d7-02ea3cbf9433",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Mobility is one of the fundamental requirement...\n",
              "1    The recent rise of the political extremism in ...\n",
              "2    The power of the press to shape the informatio...\n",
              "3    Identifying influential nodes in a network is ...\n",
              "4    To complement traditional dietary surveys, whi...\n",
              "Name: Abstract, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "scopus = pd.read_csv(\"https://raw.githubusercontent.com/jdvelasq/datalabs/master/datasets/scopus-abstracts.csv\")\n",
        "scopus['Abstract'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6889572-587b-4c6f-a60e-88baae0d2603",
      "metadata": {
        "id": "e6889572-587b-4c6f-a60e-88baae0d2603"
      },
      "source": [
        "Descripción del problema\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11b735e5-e97a-4492-b216-70f3e59da6e5",
      "metadata": {
        "id": "11b735e5-e97a-4492-b216-70f3e59da6e5"
      },
      "source": [
        "Uno de los principales problemas abordados en minería de texto consiste en la extracción de los temas o tópicos a los que pertenece documento. Por ejemplo, una noticia podría pertener simultáneamente a los temas de religión y economía (el escándalo por el manejo de fondos del Vaticano). Cuando se tiene un conjunto de documentos, se desea extraer los tópicos subyacentes sobre los que tratan los documentos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e283e75d-d9f0-438a-9e32-4122777d5e50",
      "metadata": {
        "id": "e283e75d-d9f0-438a-9e32-4122777d5e50"
      },
      "source": [
        "Scikit-learn contiene una implementación de la metodología Latent Dirichlet Allocation, la cual permite extraer los tópicos de un conjunto de documentos. Véase https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b577cb58-f6d9-4e98-9310-0a56fb931840",
      "metadata": {
        "id": "b577cb58-f6d9-4e98-9310-0a56fb931840"
      },
      "source": [
        "Utilice esta metodología para extraer los tópicos subyacentes en los abstracts de los artículos. Tenga en cuenta que:\n",
        "\n",
        "1. Debe establecer como obtener el número apropiado de tópicos a obtener.\n",
        "\n",
        "2. Debe eliminar las stop-words.\n",
        "\n",
        "3. En T-Lab sugieren reducir las palabras a sustantivos, adjetivos, verbos y adverbios únicamente. Cómo podría realizar esto en su código=?\n",
        "\n",
        "4. Cómo podría verificar si la cantidad de temas es apropiada desde el punto de vista de su contenido (las palabras que contiene y los temas que trata)?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install update sklearn\n",
        "import numpy as np\n",
        "import re, nltk, spacy, gensim\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pprint import pprint\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZBNtvMtCKAC",
        "outputId": "28495982-967a-490b-d52d-cb5dd38fb0e3"
      },
      "id": "2ZBNtvMtCKAC",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: update in c:\\users\\jlope\\anaconda3\\lib\\site-packages (0.0.1)\n",
            "Requirement already satisfied: sklearn in c:\\users\\jlope\\anaconda3\\lib\\site-packages (0.0)\n",
            "Requirement already satisfied: style==1.1.0 in c:\\users\\jlope\\anaconda3\\lib\\site-packages (from update) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\jlope\\anaconda3\\lib\\site-packages (from sklearn) (0.24.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\jlope\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.20.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jlope\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\jlope\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\jlope\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = scopus['Abstract'].values.tolist()\n",
        "df = [re.sub(r'\\S*@\\S*\\s?', '', sent) for sent in df]\n",
        "df = [re.sub(r'\\s+', ' ', sent) for sent in df]\n",
        "df = [re.sub(r\"\\'\", \"\", sent) for sent in df]\n",
        "pprint(df[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izi9okAjHGrS",
        "outputId": "0a35ba0f-b5aa-4ed5-cd7e-013fc856d921"
      },
      "id": "izi9okAjHGrS",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mobility is one of the fundamental requirements of human life with '\n",
            " 'significant societal impacts including productivity, economy, social '\n",
            " 'wellbeing, adaptation to a changing climate, and so on. Although human '\n",
            " 'movements follow specific patterns during normal periods, there are limited '\n",
            " 'studies on how such patterns change due to extreme events. To quantify the '\n",
            " 'impacts of an extreme event to human movements, we introduce the concept of '\n",
            " 'mobility resilience which is defined as the ability of a mobility system to '\n",
            " 'manage shocks and return to a steady state in response to an extreme event. '\n",
            " 'We present a method to detect extreme events from geo-located movement data '\n",
            " 'and to measure mobility resilience and transient loss of resilience due to '\n",
            " 'those events. Applying this method, we measure resilience metrics from '\n",
            " 'geo-located social media data for multiple types of disasters occurred all '\n",
            " 'over the world. Quantifying mobility resilience may help us to assess the '\n",
            " 'higher-order socio-economic impacts of extreme events and guide policies '\n",
            " 'towards developing resilient infrastructures as well as a nation’s overall '\n",
            " 'disaster resilience strategies. © 2019, The Author(s).']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_to_words(oraciones):\n",
        "  for oracion in oraciones:\n",
        "    yield(gensim.utils.simple_preprocess(str(oracion), deacc=True))\n",
        "\n",
        "data_words = list(sent_to_words(df))\n",
        "print(data_words[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKSUISZbLIlT",
        "outputId": "320f7596-8784-4256-8f20-8d8ce5bec7a1"
      },
      "id": "iKSUISZbLIlT",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['mobility', 'is', 'one', 'of', 'the', 'fundamental', 'requirements', 'of', 'human', 'life', 'with', 'significant', 'societal', 'impacts', 'including', 'productivity', 'economy', 'social', 'wellbeing', 'adaptation', 'to', 'changing', 'climate', 'and', 'so', 'on', 'although', 'human', 'movements', 'follow', 'specific', 'patterns', 'during', 'normal', 'periods', 'there', 'are', 'limited', 'studies', 'on', 'how', 'such', 'patterns', 'change', 'due', 'to', 'extreme', 'events', 'to', 'quantify', 'the', 'impacts', 'of', 'an', 'extreme', 'event', 'to', 'human', 'movements', 'we', 'introduce', 'the', 'concept', 'of', 'mobility', 'resilience', 'which', 'is', 'defined', 'as', 'the', 'ability', 'of', 'mobility', 'system', 'to', 'manage', 'shocks', 'and', 'return', 'to', 'steady', 'state', 'in', 'response', 'to', 'an', 'extreme', 'event', 'we', 'present', 'method', 'to', 'detect', 'extreme', 'events', 'from', 'geo', 'located', 'movement', 'data', 'and', 'to', 'measure', 'mobility', 'resilience', 'and', 'transient', 'loss', 'of', 'resilience', 'due', 'to', 'those', 'events', 'applying', 'this', 'method', 'we', 'measure', 'resilience', 'metrics', 'from', 'geo', 'located', 'social', 'media', 'data', 'for', 'multiple', 'types', 'of', 'disasters', 'occurred', 'all', 'over', 'the', 'world', 'quantifying', 'mobility', 'resilience', 'may', 'help', 'us', 'to', 'assess', 'the', 'higher', 'order', 'socio', 'economic', 'impacts', 'of', 'extreme', 'events', 'and', 'guide', 'policies', 'towards', 'developing', 'resilient', 'infrastructures', 'as', 'well', 'as', 'nation', 'overall', 'disaster', 'resilience', 'strategies', 'the', 'author']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.cli.download import download\n",
        "download(model=\"en_core_web_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDidFPO7TEOt",
        "outputId": "60cc2735-d9ac-4a13-b95b-0265f2fb9377"
      },
      "id": "dDidFPO7TEOt",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Download and installation successful\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatization(texts, allowed_postags=['NOUN', \"ADJ\" , 'VERB' 'ADV']):\n",
        "  texts_out = []\n",
        "  for sent in texts:\n",
        "    doc = nlp(\" \".join(sent))\n",
        "    texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
        "  return texts_out\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "print(data_lemmatized[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsIem76CM3W5",
        "outputId": "bacedf6a-6341-4cd7-f5af-3453206a7eef"
      },
      "id": "WsIem76CM3W5",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mobility fundamental requirement human life significant societal impact include productivity economy social wellbeing adaptation change climate so human movement follow specific pattern normal period limited study such pattern change extreme event quantify impact extreme event human movement introduce concept mobility resilience define ability mobility system manage shock return steady state response extreme event present method detect extreme event locate movement datum measure mobility resilience transient loss resilience event apply method measure resilience metric locate social medium datum multiple type disaster occur all world quantify mobility resilience help assess high order socio economic impact extreme event guide policy develop resilient infrastructure as well nation overall disaster resilience strategy author', 'recent rise political extremism western country spur renew interest psychological moral appeal political extremism empirical support psychological explanation use survey limit lack access extremist group field study miss psychological measure fail compare extremist contrast group revisit debate psychological moral appeal extremism context analyze twitter datum political extremist compare text base psychological construct liberal conservative user result reveal extremist show low positive emotion high negative emotion partisan user difference certainty significant addition left wing extremist express more language indicative anxiety liberal right wing extremist express low anxiety conservative moreover result mostly lend support moral foundation theory partisan user extend political extremist exception ingroup loyalty find evidence support moral foundation theory left right wing extremist however find evidence elevated moral foundation political extremist author']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(analyzer='word',       \n",
        "                             min_df=10,# minimum reqd occurences of a word \n",
        "                             stop_words='english', # remove stop words\n",
        "                             lowercase=True, # convert all words to lowercase\n",
        "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
        "                             # max_features=50000,    # max number of uniq words    \n",
        "                            )\n",
        "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
      ],
      "metadata": {
        "id": "upBQnpqaOBH3"
      },
      "id": "upBQnpqaOBH3",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "terms = vectorizer.get_feature_names()\n",
        "len(terms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhlAdeP_OzL1",
        "outputId": "77fbc377-2e7a-43f9-b710-da52540737d7"
      },
      "id": "DhlAdeP_OzL1",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1922"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = LatentDirichletAllocation(n_components=20,           \n",
        "                                      max_iter=10,               \n",
        "                                      learning_method='online',  \n",
        "                                      random_state=100,          \n",
        "                                      # batch_size=128,           \n",
        "                                      evaluate_every = -1,       \n",
        "                                      n_jobs = -1,               \n",
        "                                     )\n",
        "\n",
        "lda_output = lda_model.fit_transform(data_vectorized)\n",
        "print(lda_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbJrKsECO4GT",
        "outputId": "461fdc09-8138-4b24-b138-15b81236518e"
      },
      "id": "VbJrKsECO4GT",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LatentDirichletAllocation(learning_method='online', n_components=20, n_jobs=-1,\n",
            "                          random_state=100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
        "pprint(lda_model.get_params())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvmIHo3qPC3y",
        "outputId": "9c9197f0-e523-4f4b-94fd-42e1c194afd6"
      },
      "id": "MvmIHo3qPC3y",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity:  898.8162130082914\n",
            "{'batch_size': 128,\n",
            " 'doc_topic_prior': None,\n",
            " 'evaluate_every': -1,\n",
            " 'learning_decay': 0.7,\n",
            " 'learning_method': 'online',\n",
            " 'learning_offset': 10.0,\n",
            " 'max_doc_update_iter': 100,\n",
            " 'max_iter': 10,\n",
            " 'mean_change_tol': 0.001,\n",
            " 'n_components': 20,\n",
            " 'n_jobs': -1,\n",
            " 'perp_tol': 0.1,\n",
            " 'random_state': 100,\n",
            " 'topic_word_prior': None,\n",
            " 'total_samples': 1000000.0,\n",
            " 'verbose': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_params = {'n_components': [5, 15, 20], 'learning_decay': [.5, .7, .9]}\n",
        "\n",
        "lda = LatentDirichletAllocation(max_iter=5, learning_method='online', learning_offset=50.,random_state=0, n_jobs=-1)\n",
        "\n",
        "model = GridSearchCV(lda, param_grid= search_params)\n",
        "\n",
        "model.fit(data_vectorized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9ZSyfoEPSRe",
        "outputId": "82f241bb-3166-4b27-886b-82a6a883bac0"
      },
      "id": "r9ZSyfoEPSRe",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=LatentDirichletAllocation(learning_method='online',\n",
              "                                                 learning_offset=50.0,\n",
              "                                                 max_iter=5, n_jobs=-1,\n",
              "                                                 random_state=0),\n",
              "             param_grid={'learning_decay': [0.5, 0.7, 0.9],\n",
              "                         'n_components': [5, 15, 20]})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_lda_model = model.best_estimator_\n",
        "\n",
        "print(\"Best Model's Params: \", model.best_params_)\n",
        "\n",
        "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
        "\n",
        "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFKd31EePnYl",
        "outputId": "6a9823cb-75f9-4f44-8b52-5e43561649cc"
      },
      "id": "aFKd31EePnYl",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model's Params:  {'learning_decay': 0.9, 'n_components': 5}\n",
            "Best Log Likelihood Score:  -221185.4868462772\n",
            "Model Perplexity:  959.4663154284198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_output = best_lda_model.transform(data_vectorized)\n",
        "# column names\n",
        "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_components)]\n",
        "# index names\n",
        "docnames = [\"Doc\" + str(i) for i in range(len(df))]\n",
        "# Make the pandas dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
        "# Get dominant topic for each document\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "# Styling\n",
        "def color_green(val):\n",
        " color = 'green' if val > .1 else 'black'\n",
        " return 'color: {col}'.format(col=color)\n",
        "def make_bold(val):\n",
        " weight = 700 if val > .1 else 400\n",
        " return 'font-weight: {weight}'.format(weight=weight)\n",
        "# Apply Style\n",
        "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
        "df_document_topics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "N9BG6wTqTb8j",
        "outputId": "0bf0c51b-f7ea-4dfd-95bd-2a1f5ff317d6"
      },
      "id": "N9BG6wTqTb8j",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x2784af07c40>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_5724d_row0_col0, #T_5724d_row0_col2, #T_5724d_row0_col4, #T_5724d_row1_col0, #T_5724d_row1_col2, #T_5724d_row2_col0, #T_5724d_row2_col1, #T_5724d_row2_col2, #T_5724d_row2_col4, #T_5724d_row3_col0, #T_5724d_row3_col1, #T_5724d_row3_col2, #T_5724d_row3_col4, #T_5724d_row4_col0, #T_5724d_row4_col2, #T_5724d_row4_col4, #T_5724d_row5_col0, #T_5724d_row5_col2, #T_5724d_row6_col0, #T_5724d_row6_col2, #T_5724d_row6_col4, #T_5724d_row7_col0, #T_5724d_row7_col2, #T_5724d_row7_col4, #T_5724d_row8_col0, #T_5724d_row8_col2, #T_5724d_row8_col4, #T_5724d_row9_col0, #T_5724d_row9_col1, #T_5724d_row9_col2, #T_5724d_row10_col0, #T_5724d_row10_col2, #T_5724d_row10_col4, #T_5724d_row11_col0, #T_5724d_row11_col2, #T_5724d_row11_col4, #T_5724d_row12_col0, #T_5724d_row12_col1, #T_5724d_row12_col2, #T_5724d_row12_col4, #T_5724d_row13_col0, #T_5724d_row13_col2, #T_5724d_row13_col4, #T_5724d_row14_col0, #T_5724d_row14_col2, #T_5724d_row14_col4 {\n",
              "  color: black;\n",
              "  font-weight: 400;\n",
              "}\n",
              "#T_5724d_row0_col1, #T_5724d_row0_col3, #T_5724d_row0_col5, #T_5724d_row1_col1, #T_5724d_row1_col3, #T_5724d_row1_col4, #T_5724d_row1_col5, #T_5724d_row2_col3, #T_5724d_row2_col5, #T_5724d_row3_col3, #T_5724d_row3_col5, #T_5724d_row4_col1, #T_5724d_row4_col3, #T_5724d_row4_col5, #T_5724d_row5_col1, #T_5724d_row5_col3, #T_5724d_row5_col4, #T_5724d_row5_col5, #T_5724d_row6_col1, #T_5724d_row6_col3, #T_5724d_row6_col5, #T_5724d_row7_col1, #T_5724d_row7_col3, #T_5724d_row7_col5, #T_5724d_row8_col1, #T_5724d_row8_col3, #T_5724d_row8_col5, #T_5724d_row9_col3, #T_5724d_row9_col4, #T_5724d_row9_col5, #T_5724d_row10_col1, #T_5724d_row10_col3, #T_5724d_row10_col5, #T_5724d_row11_col1, #T_5724d_row11_col3, #T_5724d_row11_col5, #T_5724d_row12_col3, #T_5724d_row12_col5, #T_5724d_row13_col1, #T_5724d_row13_col3, #T_5724d_row13_col5, #T_5724d_row14_col1, #T_5724d_row14_col3, #T_5724d_row14_col5 {\n",
              "  color: green;\n",
              "  font-weight: 700;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_5724d_\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >Topic0</th>\n",
              "      <th class=\"col_heading level0 col1\" >Topic1</th>\n",
              "      <th class=\"col_heading level0 col2\" >Topic2</th>\n",
              "      <th class=\"col_heading level0 col3\" >Topic3</th>\n",
              "      <th class=\"col_heading level0 col4\" >Topic4</th>\n",
              "      <th class=\"col_heading level0 col5\" >dominant_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row0\" class=\"row_heading level0 row0\" >Doc0</th>\n",
              "      <td id=\"T_5724d_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row0_col1\" class=\"data row0 col1\" >0.550000</td>\n",
              "      <td id=\"T_5724d_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row0_col3\" class=\"data row0 col3\" >0.440000</td>\n",
              "      <td id=\"T_5724d_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row0_col5\" class=\"data row0 col5\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row1\" class=\"row_heading level0 row1\" >Doc1</th>\n",
              "      <td id=\"T_5724d_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row1_col1\" class=\"data row1 col1\" >0.400000</td>\n",
              "      <td id=\"T_5724d_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row1_col3\" class=\"data row1 col3\" >0.330000</td>\n",
              "      <td id=\"T_5724d_row1_col4\" class=\"data row1 col4\" >0.260000</td>\n",
              "      <td id=\"T_5724d_row1_col5\" class=\"data row1 col5\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row2\" class=\"row_heading level0 row2\" >Doc2</th>\n",
              "      <td id=\"T_5724d_row2_col0\" class=\"data row2 col0\" >0.080000</td>\n",
              "      <td id=\"T_5724d_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row2_col3\" class=\"data row2 col3\" >0.910000</td>\n",
              "      <td id=\"T_5724d_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row2_col5\" class=\"data row2 col5\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row3\" class=\"row_heading level0 row3\" >Doc3</th>\n",
              "      <td id=\"T_5724d_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row3_col2\" class=\"data row3 col2\" >0.050000</td>\n",
              "      <td id=\"T_5724d_row3_col3\" class=\"data row3 col3\" >0.950000</td>\n",
              "      <td id=\"T_5724d_row3_col4\" class=\"data row3 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row3_col5\" class=\"data row3 col5\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row4\" class=\"row_heading level0 row4\" >Doc4</th>\n",
              "      <td id=\"T_5724d_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row4_col1\" class=\"data row4 col1\" >0.330000</td>\n",
              "      <td id=\"T_5724d_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row4_col3\" class=\"data row4 col3\" >0.670000</td>\n",
              "      <td id=\"T_5724d_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row4_col5\" class=\"data row4 col5\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row5\" class=\"row_heading level0 row5\" >Doc5</th>\n",
              "      <td id=\"T_5724d_row5_col0\" class=\"data row5 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row5_col1\" class=\"data row5 col1\" >0.140000</td>\n",
              "      <td id=\"T_5724d_row5_col2\" class=\"data row5 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row5_col3\" class=\"data row5 col3\" >0.500000</td>\n",
              "      <td id=\"T_5724d_row5_col4\" class=\"data row5 col4\" >0.360000</td>\n",
              "      <td id=\"T_5724d_row5_col5\" class=\"data row5 col5\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row6\" class=\"row_heading level0 row6\" >Doc6</th>\n",
              "      <td id=\"T_5724d_row6_col0\" class=\"data row6 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row6_col1\" class=\"data row6 col1\" >0.210000</td>\n",
              "      <td id=\"T_5724d_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row6_col3\" class=\"data row6 col3\" >0.780000</td>\n",
              "      <td id=\"T_5724d_row6_col4\" class=\"data row6 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row6_col5\" class=\"data row6 col5\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row7\" class=\"row_heading level0 row7\" >Doc7</th>\n",
              "      <td id=\"T_5724d_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row7_col1\" class=\"data row7 col1\" >0.720000</td>\n",
              "      <td id=\"T_5724d_row7_col2\" class=\"data row7 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row7_col3\" class=\"data row7 col3\" >0.270000</td>\n",
              "      <td id=\"T_5724d_row7_col4\" class=\"data row7 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row7_col5\" class=\"data row7 col5\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row8\" class=\"row_heading level0 row8\" >Doc8</th>\n",
              "      <td id=\"T_5724d_row8_col0\" class=\"data row8 col0\" >0.100000</td>\n",
              "      <td id=\"T_5724d_row8_col1\" class=\"data row8 col1\" >0.160000</td>\n",
              "      <td id=\"T_5724d_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row8_col3\" class=\"data row8 col3\" >0.740000</td>\n",
              "      <td id=\"T_5724d_row8_col4\" class=\"data row8 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row8_col5\" class=\"data row8 col5\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row9\" class=\"row_heading level0 row9\" >Doc9</th>\n",
              "      <td id=\"T_5724d_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row9_col1\" class=\"data row9 col1\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row9_col2\" class=\"data row9 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row9_col3\" class=\"data row9 col3\" >0.700000</td>\n",
              "      <td id=\"T_5724d_row9_col4\" class=\"data row9 col4\" >0.290000</td>\n",
              "      <td id=\"T_5724d_row9_col5\" class=\"data row9 col5\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row10\" class=\"row_heading level0 row10\" >Doc10</th>\n",
              "      <td id=\"T_5724d_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row10_col1\" class=\"data row10 col1\" >0.390000</td>\n",
              "      <td id=\"T_5724d_row10_col2\" class=\"data row10 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row10_col3\" class=\"data row10 col3\" >0.600000</td>\n",
              "      <td id=\"T_5724d_row10_col4\" class=\"data row10 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row10_col5\" class=\"data row10 col5\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row11\" class=\"row_heading level0 row11\" >Doc11</th>\n",
              "      <td id=\"T_5724d_row11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row11_col1\" class=\"data row11 col1\" >0.500000</td>\n",
              "      <td id=\"T_5724d_row11_col2\" class=\"data row11 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row11_col3\" class=\"data row11 col3\" >0.490000</td>\n",
              "      <td id=\"T_5724d_row11_col4\" class=\"data row11 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row11_col5\" class=\"data row11 col5\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row12\" class=\"row_heading level0 row12\" >Doc12</th>\n",
              "      <td id=\"T_5724d_row12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row12_col1\" class=\"data row12 col1\" >0.090000</td>\n",
              "      <td id=\"T_5724d_row12_col2\" class=\"data row12 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row12_col3\" class=\"data row12 col3\" >0.900000</td>\n",
              "      <td id=\"T_5724d_row12_col4\" class=\"data row12 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row12_col5\" class=\"data row12 col5\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row13\" class=\"row_heading level0 row13\" >Doc13</th>\n",
              "      <td id=\"T_5724d_row13_col0\" class=\"data row13 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row13_col1\" class=\"data row13 col1\" >0.270000</td>\n",
              "      <td id=\"T_5724d_row13_col2\" class=\"data row13 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row13_col3\" class=\"data row13 col3\" >0.730000</td>\n",
              "      <td id=\"T_5724d_row13_col4\" class=\"data row13 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row13_col5\" class=\"data row13 col5\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5724d_level0_row14\" class=\"row_heading level0 row14\" >Doc14</th>\n",
              "      <td id=\"T_5724d_row14_col0\" class=\"data row14 col0\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row14_col1\" class=\"data row14 col1\" >0.880000</td>\n",
              "      <td id=\"T_5724d_row14_col2\" class=\"data row14 col2\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row14_col3\" class=\"data row14 col3\" >0.110000</td>\n",
              "      <td id=\"T_5724d_row14_col4\" class=\"data row14 col4\" >0.000000</td>\n",
              "      <td id=\"T_5724d_row14_col5\" class=\"data row14 col5\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Topic-Keyword Matrix\n",
        "df_topic_keywords = pd.DataFrame(best_lda_model.components_)\n",
        "# Assign Column and Index\n",
        "df_topic_keywords.columns = vectorizer.get_feature_names()\n",
        "df_topic_keywords.index = topicnames\n",
        "# View\n",
        "df_topic_keywords.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "CIZMPFVTTwtx",
        "outputId": "a3896e61-7da1-4c04-c370-4f01aab93cc2"
      },
      "id": "CIZMPFVTTwtx",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ability       able   absence   absolute   abstract  abstraction  \\\n",
              "Topic0   0.909355   0.435530  0.537895   0.369771   0.391856     0.402318   \n",
              "Topic1  50.411479  78.782597  8.718895   3.929591  10.831954    10.446974   \n",
              "Topic2   0.522230   0.773577  0.540997   0.375916  20.237580     0.778936   \n",
              "Topic3  11.912606   5.363951  4.184853   2.219846   0.445316     0.485597   \n",
              "Topic4   0.687870   0.777564  0.991189  15.018366   0.494508     0.383417   \n",
              "\n",
              "        academia   academic  accelerate     accept  ...     worker   workflow  \\\n",
              "Topic0  0.474055   0.395465    0.436576   0.402029  ...   0.356935   0.425430   \n",
              "Topic1  7.528221  40.303384    7.054471  12.866006  ...  11.993762  40.866757   \n",
              "Topic2  0.405473   0.482674    0.800995   1.110195  ...   0.457531   0.821699   \n",
              "Topic3  0.625307   1.172708    5.207437   3.759635  ...   5.827326   0.399765   \n",
              "Topic4  0.399504   0.449376    1.149956   0.589491  ...   0.400032   0.466397   \n",
              "\n",
              "         workload       world  worldwide      write        xml        year  \\\n",
              "Topic0   0.398075    0.778370   0.521665   0.506597   0.384371    1.425275   \n",
              "Topic1  18.457291  156.059230  13.371734  18.750486  26.929522  129.495695   \n",
              "Topic2   1.915001    6.553050   0.478576   0.964505   1.573274    0.941511   \n",
              "Topic3   0.439451   18.492856   6.728381   1.691497   0.351588   26.123051   \n",
              "Topic4   0.479599    4.335735   2.342602   0.585452   0.542717   20.538310   \n",
              "\n",
              "            yield       zone  \n",
              "Topic0   0.813200   0.999218  \n",
              "Topic1  29.909533   9.396929  \n",
              "Topic2   0.802976   0.559309  \n",
              "Topic3   7.090182  14.716786  \n",
              "Topic4   1.509716   0.420081  \n",
              "\n",
              "[5 rows x 1922 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>absence</th>\n",
              "      <th>absolute</th>\n",
              "      <th>abstract</th>\n",
              "      <th>abstraction</th>\n",
              "      <th>academia</th>\n",
              "      <th>academic</th>\n",
              "      <th>accelerate</th>\n",
              "      <th>accept</th>\n",
              "      <th>...</th>\n",
              "      <th>worker</th>\n",
              "      <th>workflow</th>\n",
              "      <th>workload</th>\n",
              "      <th>world</th>\n",
              "      <th>worldwide</th>\n",
              "      <th>write</th>\n",
              "      <th>xml</th>\n",
              "      <th>year</th>\n",
              "      <th>yield</th>\n",
              "      <th>zone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic0</th>\n",
              "      <td>0.909355</td>\n",
              "      <td>0.435530</td>\n",
              "      <td>0.537895</td>\n",
              "      <td>0.369771</td>\n",
              "      <td>0.391856</td>\n",
              "      <td>0.402318</td>\n",
              "      <td>0.474055</td>\n",
              "      <td>0.395465</td>\n",
              "      <td>0.436576</td>\n",
              "      <td>0.402029</td>\n",
              "      <td>...</td>\n",
              "      <td>0.356935</td>\n",
              "      <td>0.425430</td>\n",
              "      <td>0.398075</td>\n",
              "      <td>0.778370</td>\n",
              "      <td>0.521665</td>\n",
              "      <td>0.506597</td>\n",
              "      <td>0.384371</td>\n",
              "      <td>1.425275</td>\n",
              "      <td>0.813200</td>\n",
              "      <td>0.999218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic1</th>\n",
              "      <td>50.411479</td>\n",
              "      <td>78.782597</td>\n",
              "      <td>8.718895</td>\n",
              "      <td>3.929591</td>\n",
              "      <td>10.831954</td>\n",
              "      <td>10.446974</td>\n",
              "      <td>7.528221</td>\n",
              "      <td>40.303384</td>\n",
              "      <td>7.054471</td>\n",
              "      <td>12.866006</td>\n",
              "      <td>...</td>\n",
              "      <td>11.993762</td>\n",
              "      <td>40.866757</td>\n",
              "      <td>18.457291</td>\n",
              "      <td>156.059230</td>\n",
              "      <td>13.371734</td>\n",
              "      <td>18.750486</td>\n",
              "      <td>26.929522</td>\n",
              "      <td>129.495695</td>\n",
              "      <td>29.909533</td>\n",
              "      <td>9.396929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic2</th>\n",
              "      <td>0.522230</td>\n",
              "      <td>0.773577</td>\n",
              "      <td>0.540997</td>\n",
              "      <td>0.375916</td>\n",
              "      <td>20.237580</td>\n",
              "      <td>0.778936</td>\n",
              "      <td>0.405473</td>\n",
              "      <td>0.482674</td>\n",
              "      <td>0.800995</td>\n",
              "      <td>1.110195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.457531</td>\n",
              "      <td>0.821699</td>\n",
              "      <td>1.915001</td>\n",
              "      <td>6.553050</td>\n",
              "      <td>0.478576</td>\n",
              "      <td>0.964505</td>\n",
              "      <td>1.573274</td>\n",
              "      <td>0.941511</td>\n",
              "      <td>0.802976</td>\n",
              "      <td>0.559309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic3</th>\n",
              "      <td>11.912606</td>\n",
              "      <td>5.363951</td>\n",
              "      <td>4.184853</td>\n",
              "      <td>2.219846</td>\n",
              "      <td>0.445316</td>\n",
              "      <td>0.485597</td>\n",
              "      <td>0.625307</td>\n",
              "      <td>1.172708</td>\n",
              "      <td>5.207437</td>\n",
              "      <td>3.759635</td>\n",
              "      <td>...</td>\n",
              "      <td>5.827326</td>\n",
              "      <td>0.399765</td>\n",
              "      <td>0.439451</td>\n",
              "      <td>18.492856</td>\n",
              "      <td>6.728381</td>\n",
              "      <td>1.691497</td>\n",
              "      <td>0.351588</td>\n",
              "      <td>26.123051</td>\n",
              "      <td>7.090182</td>\n",
              "      <td>14.716786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic4</th>\n",
              "      <td>0.687870</td>\n",
              "      <td>0.777564</td>\n",
              "      <td>0.991189</td>\n",
              "      <td>15.018366</td>\n",
              "      <td>0.494508</td>\n",
              "      <td>0.383417</td>\n",
              "      <td>0.399504</td>\n",
              "      <td>0.449376</td>\n",
              "      <td>1.149956</td>\n",
              "      <td>0.589491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.400032</td>\n",
              "      <td>0.466397</td>\n",
              "      <td>0.479599</td>\n",
              "      <td>4.335735</td>\n",
              "      <td>2.342602</td>\n",
              "      <td>0.585452</td>\n",
              "      <td>0.542717</td>\n",
              "      <td>20.538310</td>\n",
              "      <td>1.509716</td>\n",
              "      <td>0.420081</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1922 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show top n keywords for each topic\n",
        "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=20):\n",
        "    keywords = np.array(vectorizer.get_feature_names())\n",
        "    topic_keywords = []\n",
        "    for topic_weights in lda_model.components_:\n",
        "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
        "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
        "    return topic_keywords\n",
        "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=best_lda_model, n_words=15)\n",
        "# Topic - Keywords Dataframe\n",
        "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
        "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
        "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
        "df_topic_keywords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "W5t_RywzT0K9",
        "outputId": "370aecb3-ee49-4c66-be7d-3d6fb4631bd6"
      },
      "id": "W5t_RywzT0K9",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Word 0       Word 1     Word 2   Word 3       Word 4   Word 5  \\\n",
              "Topic 0        stock     investor  financial  opinion  probability    datum   \n",
              "Topic 1        datum          use      model   method         base  propose   \n",
              "Topic 2        graph        query   database    datum       method     file   \n",
              "Topic 3        urban          use      model    study      network     city   \n",
              "Topic 4  geomagnetic  observatory   variable    datum     magnetic    polar   \n",
              "\n",
              "              Word 6         Word 7   Word 8    Word 9   Word 10  \\\n",
              "Topic 0         news           home    price  regional   analyst   \n",
              "Topic 1        paper    information   result      time  research   \n",
              "Topic 2         core      available     edge      cube     large   \n",
              "Topic 3     economic      different   result    author    social   \n",
              "Topic 4  observation  international  project      year    record   \n",
              "\n",
              "              Word 11     Word 12 Word 13    Word 14  \n",
              "Topic 0         trade    behavior    code   research  \n",
              "Topic 1      approach    analysis     big      study  \n",
              "Topic 2      abstract  repository  schema    propose  \n",
              "Topic 3         paper    analysis    area   customer  \n",
              "Topic 4  magnetometer       field   solar  satellite  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word 0</th>\n",
              "      <th>Word 1</th>\n",
              "      <th>Word 2</th>\n",
              "      <th>Word 3</th>\n",
              "      <th>Word 4</th>\n",
              "      <th>Word 5</th>\n",
              "      <th>Word 6</th>\n",
              "      <th>Word 7</th>\n",
              "      <th>Word 8</th>\n",
              "      <th>Word 9</th>\n",
              "      <th>Word 10</th>\n",
              "      <th>Word 11</th>\n",
              "      <th>Word 12</th>\n",
              "      <th>Word 13</th>\n",
              "      <th>Word 14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Topic 0</th>\n",
              "      <td>stock</td>\n",
              "      <td>investor</td>\n",
              "      <td>financial</td>\n",
              "      <td>opinion</td>\n",
              "      <td>probability</td>\n",
              "      <td>datum</td>\n",
              "      <td>news</td>\n",
              "      <td>home</td>\n",
              "      <td>price</td>\n",
              "      <td>regional</td>\n",
              "      <td>analyst</td>\n",
              "      <td>trade</td>\n",
              "      <td>behavior</td>\n",
              "      <td>code</td>\n",
              "      <td>research</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 1</th>\n",
              "      <td>datum</td>\n",
              "      <td>use</td>\n",
              "      <td>model</td>\n",
              "      <td>method</td>\n",
              "      <td>base</td>\n",
              "      <td>propose</td>\n",
              "      <td>paper</td>\n",
              "      <td>information</td>\n",
              "      <td>result</td>\n",
              "      <td>time</td>\n",
              "      <td>research</td>\n",
              "      <td>approach</td>\n",
              "      <td>analysis</td>\n",
              "      <td>big</td>\n",
              "      <td>study</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 2</th>\n",
              "      <td>graph</td>\n",
              "      <td>query</td>\n",
              "      <td>database</td>\n",
              "      <td>datum</td>\n",
              "      <td>method</td>\n",
              "      <td>file</td>\n",
              "      <td>core</td>\n",
              "      <td>available</td>\n",
              "      <td>edge</td>\n",
              "      <td>cube</td>\n",
              "      <td>large</td>\n",
              "      <td>abstract</td>\n",
              "      <td>repository</td>\n",
              "      <td>schema</td>\n",
              "      <td>propose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 3</th>\n",
              "      <td>urban</td>\n",
              "      <td>use</td>\n",
              "      <td>model</td>\n",
              "      <td>study</td>\n",
              "      <td>network</td>\n",
              "      <td>city</td>\n",
              "      <td>economic</td>\n",
              "      <td>different</td>\n",
              "      <td>result</td>\n",
              "      <td>author</td>\n",
              "      <td>social</td>\n",
              "      <td>paper</td>\n",
              "      <td>analysis</td>\n",
              "      <td>area</td>\n",
              "      <td>customer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Topic 4</th>\n",
              "      <td>geomagnetic</td>\n",
              "      <td>observatory</td>\n",
              "      <td>variable</td>\n",
              "      <td>datum</td>\n",
              "      <td>magnetic</td>\n",
              "      <td>polar</td>\n",
              "      <td>observation</td>\n",
              "      <td>international</td>\n",
              "      <td>project</td>\n",
              "      <td>year</td>\n",
              "      <td>record</td>\n",
              "      <td>magnetometer</td>\n",
              "      <td>field</td>\n",
              "      <td>solar</td>\n",
              "      <td>satellite</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "08-003-latent_dirichlet_allocation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}